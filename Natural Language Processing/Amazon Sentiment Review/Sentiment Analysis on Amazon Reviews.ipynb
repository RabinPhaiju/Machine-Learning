{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from tensorflow.python.keras import models, layers, optimizers\r\n",
    "import tensorflow\r\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer, text_to_word_sequence\r\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\r\n",
    "import bz2\r\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\r\n",
    "import re\r\n",
    "\r\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Creating a function to load the text and labels from train and test set\r\n",
    "\r\n",
    "def get_labels_and_texts(file):\r\n",
    "    labels = []\r\n",
    "    texts = []\r\n",
    "    for line in bz2.BZ2File(file):\r\n",
    "        x = line.decode(\"utf-8\")\r\n",
    "        labels.append(int(x[9]) - 1)\r\n",
    "        texts.append(x[10:].strip())\r\n",
    "    return np.array(labels), texts\r\n",
    "file_path = 'E:/Backup/Project/Machine Learning/Natural language processing/'\r\n",
    "train_labels, train_texts = get_labels_and_texts(file_path+'train.ft.txt.bz2')\r\n",
    "test_labels, test_texts = get_labels_and_texts(file_path+'test.ft.txt.bz2')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "print('label: ',train_labels[0])\r\n",
    "train_texts[0]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label:  1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Stuning even for the non-gamer: This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# only using first 500 data\r\n",
    "train_labels=train_labels[0:500]\r\n",
    "train_texts=train_texts[0:500]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#text pre-processing\r\n",
    "import re\r\n",
    "NON_ALPHANUM = re.compile(r'[\\W]')\r\n",
    "NON_ASCII = re.compile(r'[^a-z0-1\\s]')\r\n",
    "\r\n",
    "def normalize_texts(texts):\r\n",
    "    normalized_texts = []\r\n",
    "    for text in texts:\r\n",
    "        lower = text.lower()\r\n",
    "        no_punctuation = NON_ALPHANUM.sub(r' ', lower)\r\n",
    "        no_non_ascii = NON_ASCII.sub(r'', no_punctuation)\r\n",
    "        normalized_texts.append(no_non_ascii)\r\n",
    "    return normalized_texts\r\n",
    "        \r\n",
    "train_texts = normalize_texts(train_texts)\r\n",
    "test_texts = normalize_texts(test_texts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "# countvectorizer : number of times a word occur.\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "cv = CountVectorizer(binary=True)\r\n",
    "cv.fit(train_texts)\r\n",
    "X = cv.transform(train_texts)\r\n",
    "X_test = cv.transform(test_texts)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "print(X_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  (0, 213)\t1\n",
      "  (0, 282)\t1\n",
      "  (0, 398)\t1\n",
      "  (0, 503)\t1\n",
      "  (0, 506)\t1\n",
      "  (0, 511)\t1\n",
      "  (0, 525)\t1\n",
      "  (0, 561)\t1\n",
      "  (0, 761)\t1\n",
      "  (0, 1305)\t1\n",
      "  (0, 1698)\t1\n",
      "  (0, 1701)\t1\n",
      "  (0, 1857)\t1\n",
      "  (0, 1864)\t1\n",
      "  (0, 1973)\t1\n",
      "  (0, 2090)\t1\n",
      "  (0, 2156)\t1\n",
      "  (0, 2193)\t1\n",
      "  (0, 2279)\t1\n",
      "  (0, 2288)\t1\n",
      "  (0, 2331)\t1\n",
      "  (0, 2525)\t1\n",
      "  (0, 2678)\t1\n",
      "  (0, 2681)\t1\n",
      "  (0, 2689)\t1\n",
      "  :\t:\n",
      "  (399999, 3817)\t1\n",
      "  (399999, 3987)\t1\n",
      "  (399999, 4059)\t1\n",
      "  (399999, 4194)\t1\n",
      "  (399999, 4363)\t1\n",
      "  (399999, 4413)\t1\n",
      "  (399999, 4667)\t1\n",
      "  (399999, 4773)\t1\n",
      "  (399999, 4888)\t1\n",
      "  (399999, 5087)\t1\n",
      "  (399999, 5090)\t1\n",
      "  (399999, 5094)\t1\n",
      "  (399999, 5100)\t1\n",
      "  (399999, 5104)\t1\n",
      "  (399999, 5107)\t1\n",
      "  (399999, 5125)\t1\n",
      "  (399999, 5186)\t1\n",
      "  (399999, 5191)\t1\n",
      "  (399999, 5455)\t1\n",
      "  (399999, 5540)\t1\n",
      "  (399999, 5609)\t1\n",
      "  (399999, 5610)\t1\n",
      "  (399999, 5620)\t1\n",
      "  (399999, 5649)\t1\n",
      "  (399999, 5759)\t1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "\r\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, train_labels, train_size = 0.75)\r\n",
    "\r\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:\r\n",
    "    # C : how much you want to regularize the model on to the data.\r\n",
    "    lr = LogisticRegression(C=c)\r\n",
    "    lr.fit(X_train, y_train)\r\n",
    "    print (\"Accuracy for C=%s: %s\" % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for C=0.01: 0.744\n",
      "Accuracy for C=0.05: 0.776\n",
      "Accuracy for C=0.25: 0.776\n",
      "Accuracy for C=0.5: 0.784\n",
      "Accuracy for C=1: 0.784\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "lr.predict(X_test[29])"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "print('label: ',test_labels[29])\r\n",
    "test_texts[29]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "label:  0\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'three days of use and it broke  very disappointed in this product  it worked perfectly for exactly three days and could not be resuscitated  it was very inexpensive so i did not want to pay half again the price to ship it back for an exchange  so the company would do nothing when they sent me an inquiry as to product satisfaction '"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "a456efd1d2e2bfa10bfdad488db5626e5f8bd233a0f11ae70ce0e7717a6a7d8d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}