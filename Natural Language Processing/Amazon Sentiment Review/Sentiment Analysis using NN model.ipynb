{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "import bz2\n",
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitReviewsLabels(lines):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for review in tqdm(lines):\n",
    "        rev = reviewToX(review)\n",
    "        label = reviewToY(review)\n",
    "        reviews.append(rev[:512])\n",
    "        labels.append(label)\n",
    "    return reviews, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviewToY(review):\n",
    "    return [1,0] if review.split(' ')[0] == '__label__1' else [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reviewToX(review):\n",
    "    review = review.split(' ', 1)[1][:-1].lower()\n",
    "    review = re.sub('\\d','0',review)\n",
    "    if 'www.' in review or 'http:' in review or 'https:' in review or '.com' in review:\n",
    "        review = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", review)\n",
    "    return review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bz2.BZ2File"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = 'E:/Backup/Project/Machine Learning/Natural language processing/'\n",
    "train_file = bz2.BZ2File(file_path+'train.ft.txt.bz2')\n",
    "test_file = bz2.BZ2File(file_path+'test.ft.txt.bz2')\n",
    "\n",
    "train_lines = train_file.readlines()\n",
    "test_lines = test_file.readlines()\n",
    "\n",
    "# train_lines = [x.decode('utf-8') for x in train_lines]\n",
    "# test_lines = [x.decode('utf-8') for x in test_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-75a37fc7b7c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-75a37fc7b7c1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "train_lines = [x.decode('utf-8') for x in train_lines[:15000]]\n",
    "test_lines = [x.decode('utf-8') for x in test_lines[:15000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15000/15000 [00:01<00:00, 13678.82it/s]\n",
      "100%|██████████| 15000/15000 [00:00<00:00, 29182.98it/s]\n"
     ]
    }
   ],
   "source": [
    "reviews_train, y_train = splitReviewsLabels(train_lines)\n",
    "reviews_test, y_test = splitReviewsLabels(test_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train, y_train = shuffle(reviews_train, y_train)\n",
    "reviews_test, y_test = shuffle(reviews_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 8192\n",
    "maxlen = 128\n",
    "embed_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('tokenizer.sav','wb') as handle:\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_train = tokenizer.texts_to_sequences(reviews_train)\n",
    "token_test = tokenizer.texts_to_sequences(reviews_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pad_sequences(token_train, maxlen=maxlen, padding='post')\n",
    "x_test = pad_sequences(token_test, maxlen=maxlen, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = Input(shape=(maxlen,))\n",
    "net = Embedding(max_features, embed_size)(input)\n",
    "net = Dropout(0.2)(net)\n",
    "net = BatchNormalization()(net)\n",
    "\n",
    "net = Conv1D(32, 7, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net = BatchNormalization()(net)\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\n",
    "net1 = BatchNormalization()(net)\n",
    "\n",
    "net = Conv1D(2, 1)(net)\n",
    "net = GlobalAveragePooling1D()(net)\n",
    "output = Activation('softmax')(net)\n",
    "model = Model(inputs = input, outputs = output)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.7186 - acc: 0.5336 - val_loss: 0.6941 - val_acc: 0.4927\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.6352 - acc: 0.6427 - val_loss: 0.6955 - val_acc: 0.4927\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.5164 - acc: 0.7962 - val_loss: 0.6978 - val_acc: 0.4927\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.3850 - acc: 0.8608 - val_loss: 0.7060 - val_acc: 0.4927\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.2850 - acc: 0.8981 - val_loss: 0.7245 - val_acc: 0.4927\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247093b33d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 [==============================] - 5s 11ms/step - loss: 0.7176 - acc: 0.5071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7176415920257568, 0.5071333050727844]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate (x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a456efd1d2e2bfa10bfdad488db5626e5f8bd233a0f11ae70ce0e7717a6a7d8d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
