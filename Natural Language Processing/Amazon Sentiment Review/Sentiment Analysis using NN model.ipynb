{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import re\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from tqdm import tqdm\r\n",
    "import bz2\r\n",
    "from keras.layers import *\r\n",
    "from keras.models import Model\r\n",
    "from keras.preprocessing.text import Tokenizer\r\n",
    "from keras.preprocessing.sequence import pad_sequences\r\n",
    "from sklearn.metrics import precision_recall_fscore_support,accuracy_score"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def splitReviewsLabels(lines):\r\n",
    "    reviews = []\r\n",
    "    labels = []\r\n",
    "    for review in tqdm(lines):\r\n",
    "        rev = reviewToX(review)\r\n",
    "        label = reviewToY(review)\r\n",
    "        reviews.append(rev[:512])\r\n",
    "        labels.append(label)\r\n",
    "    return reviews, labels"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "def reviewToY(review):\r\n",
    "    return [1,0] if review.split(' ')[0] == '__label__1' else [0,1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "def reviewToX(review):\r\n",
    "    review = review.split(' ', 1)[1][:-1].lower()\r\n",
    "    review = re.sub('\\d','0',review)\r\n",
    "    if 'www.' in review or 'http:' in review or 'https:' in review or '.com' in review:\r\n",
    "        review = re.sub(r\"([^ ]+(?<=\\.[a-z]{3}))\", \"<url>\", review)\r\n",
    "    return review"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "file_path = 'E:/Backup/Project/Machine Learning/Natural language processing/'\r\n",
    "train_file = bz2.BZ2File(file_path+'train.ft.txt.bz2')\r\n",
    "test_file = bz2.BZ2File(file_path+'test.ft.txt.bz2')\r\n",
    "\r\n",
    "train_lines = train_file.readlines()\r\n",
    "test_lines = test_file.readlines()\r\n",
    "\r\n",
    "# train_lines = [x.decode('utf-8') for x in train_lines]\r\n",
    "# test_lines = [x.decode('utf-8') for x in test_lines]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "bz2.BZ2File"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "train_lines = [x.decode('utf-8') for x in train_lines[:15000]]\r\n",
    "test_lines = [x.decode('utf-8') for x in test_lines[:15000]]"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-75a37fc7b7c1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-15-75a37fc7b7c1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_lines\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "reviews_train, y_train = splitReviewsLabels(train_lines)\r\n",
    "reviews_test, y_test = splitReviewsLabels(test_lines)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 15000/15000 [00:01<00:00, 13678.82it/s]\n",
      "100%|██████████| 15000/15000 [00:00<00:00, 29182.98it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "reviews_train, y_train = shuffle(reviews_train, y_train)\r\n",
    "reviews_test, y_test = shuffle(reviews_test, y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "y_train = np.array(y_train)\r\n",
    "y_test = np.array(y_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "max_features = 8192\r\n",
    "maxlen = 128\r\n",
    "embed_size = 64"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "tokenizer = Tokenizer(num_words=max_features)\r\n",
    "tokenizer.fit_on_texts(reviews_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "import pickle\r\n",
    "with open('tokenizer.sav','wb') as handle:\r\n",
    "    pickle.dump(tokenizer,handle,protocol=pickle.HIGHEST_PROTOCOL)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "token_train = tokenizer.texts_to_sequences(reviews_train)\r\n",
    "token_test = tokenizer.texts_to_sequences(reviews_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "x_train = pad_sequences(token_train, maxlen=maxlen, padding='post')\r\n",
    "x_test = pad_sequences(token_test, maxlen=maxlen, padding='post')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "input = Input(shape=(maxlen,))\r\n",
    "net = Embedding(max_features, embed_size)(input)\r\n",
    "net = Dropout(0.2)(net)\r\n",
    "net = BatchNormalization()(net)\r\n",
    "\r\n",
    "net = Conv1D(32, 7, padding='same', activation='relu')(net)\r\n",
    "net = BatchNormalization()(net)\r\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\r\n",
    "net = BatchNormalization()(net)\r\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\r\n",
    "net = BatchNormalization()(net)\r\n",
    "net = Conv1D(32, 3, padding='same', activation='relu')(net)\r\n",
    "net1 = BatchNormalization()(net)\r\n",
    "\r\n",
    "net = Conv1D(2, 1)(net)\r\n",
    "net = GlobalAveragePooling1D()(net)\r\n",
    "output = Activation('softmax')(net)\r\n",
    "model = Model(inputs = input, outputs = output)\r\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "# model.summary()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "model.fit(x_train, y_train, batch_size=2048, epochs=5, validation_split=0.1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "7/7 [==============================] - 25s 4s/step - loss: 0.7186 - acc: 0.5336 - val_loss: 0.6941 - val_acc: 0.4927\n",
      "Epoch 2/5\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.6352 - acc: 0.6427 - val_loss: 0.6955 - val_acc: 0.4927\n",
      "Epoch 3/5\n",
      "7/7 [==============================] - 21s 3s/step - loss: 0.5164 - acc: 0.7962 - val_loss: 0.6978 - val_acc: 0.4927\n",
      "Epoch 4/5\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.3850 - acc: 0.8608 - val_loss: 0.7060 - val_acc: 0.4927\n",
      "Epoch 5/5\n",
      "7/7 [==============================] - 22s 3s/step - loss: 0.2850 - acc: 0.8981 - val_loss: 0.7245 - val_acc: 0.4927\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247093b33d0>"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "model.evaluate (x_test, y_test)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "469/469 [==============================] - 5s 11ms/step - loss: 0.7176 - acc: 0.5071\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[0.7176415920257568, 0.5071333050727844]"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)"
  },
  "interpreter": {
   "hash": "a456efd1d2e2bfa10bfdad488db5626e5f8bd233a0f11ae70ce0e7717a6a7d8d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}